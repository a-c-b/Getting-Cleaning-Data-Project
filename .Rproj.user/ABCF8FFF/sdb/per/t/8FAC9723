{
    "contents" : "\n\n#Getting-Cleaning-Data-Project\n#=============================\n\n##   This is the project for the coursera course Getting and Cleaning Data.\n        \n#       Loaded into this Repo are the following documents and files:\n        \n        1) run_analysis.R script, \n        2) a Read Me markdown document, \n        3) a Code book markdown document, \n        4) and upload the final tidy data text file of the summarized results\n\n \n#      Phase 1: \n##     Load, clean, merge and name all the Test files first.\n\n        The script run_analysis.R begins with deleting any previous data sets in\n        your working directory which would be equal to what the unzipped directory\n        structure of the down load data would be.\n        \n        It then downloads the data from the source.  This data is a binary file,\n        so the download takes that into account, otherwise the unzip would not work.\n\n###  Steps:  \n\n        Load the data into temporary tables.  Make table names as close to file name \n        as possible.\n        \n        Combine tables of information to add descriptors to the dataset, including\n        readable headers and the the association to a subject and the activity label.\n        \n        Create a unique row number to merge files together and keep the association\n        of the data position through various binds, sorts, or merges.\n        \n        Merge the Activity Number with an Activity Label.  This assigns an Activity word\n        to the dataset.  \n        \n        Create the cleaned test data set by combining the subject information with the\n        activity label to the dataset.\n                \n        The activity on the Training dataset will be duplicated per the steps above.\n        \n        Merge the cleaned, labeled, activity & subject identified Test & Training\n        data tables together for a combined dataset.\n        \n        An output text file is created for this combined dataset.\n        \n        All the temporary tables, except for the single combined table, are cleared\n        from memory.\n        \n# Phase 2\n##  Extracting only the measurements on the mean and standard deviation \n##  for each measurement.\n\n        \n          This will create a second tidy dataset.  A subset of which will contain\n          only those variables out of the 564 variables in the all.data dataset\n          which have \"mean\" or \"std\" found in the header name.\n\n###  Steps:\n        \n     Get all the names of all the headers for the entire dataset so that they\n     can be returned after processing.  Put them into a temporary variable.\n     \n     Preserve the first three columns of information.  This is the identifying\n     information of the dataset regarding the data vector \"rownum\" (i.e., position\n     within the dataset), the Subject, and the word value of the Activity the Subject\n     was doing.\n     \n     Create temporary tables which consist of the columns of information which have \n     headers with the phrases \"mean\" or \"std\" in them.  These are the columns with\n     Mean or Standard Deviations applied to the Features.\n     \n     Create a new dataset of subsetted columns of information relating only to those\n     vectors which have \"mean\" or \"std\" calculations applied to the Features.  Merge \n     these columns back with the Subject and Activity vectors.  This second tidy dataset\n     is ready to process for the summation exercise in Phase 3.\n     \n     \n     \n# Phase 3\n##  Calculate the Averages for the combined datasets\n\n        Create the dataset which stores the result of the mean value\n        for all features which contained either the phrase \"mean\" or \"std\"\n        for all the subjects for each of their activities.\n        \n###  Steps:   \n\n        Create a list from the concatenation of the Subject number +\n        the Activity Label.  This variable will simplify the steps of\n        aggregation as the unique value by which all the data will \n        be averaged.\n        \n        Summarize the dataset by the value of Subject+Activity using the\n        mean function.  This creates an error on the column vectory by which\n        we were summarizing the data (SubjectActivity).  Remove this column\n        from the dataset.\n        \n        \"Put\" the names back onto the dataset to include the Subject and their\n        Activity.\n        \n        Create a sort key using the numeric value of the Subject and the Alpha-numeric\n        value of Activity.  Apply this sort key to the new dataset and sort it\n        so that the subjects will be numbered 1-30 in numerical, not character order\n        with the Activity being the tie breaker.\n        \n        Create a .txt output file of the cleaned dataset and upload that to coursera.\n        \n        \n        \n        \n        \n     \n     \n     \n     \n     \n        \n                        \n",
    "created" : 1413640615197.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "4287153361",
    "id" : "8FAC9723",
    "lastKnownWriteTime" : 1414102642,
    "path" : "~/coursera/Getting-Cleaning-Data-Project/README.md",
    "project_path" : "README.md",
    "properties" : {
        "ignored_words" : "dataset,rownum\n"
    },
    "source_on_save" : false,
    "type" : "markdown"
}