{
    "contents" : "# Code Book for Getting and Cleaning Data Project\n\n\n### by andrea345\n\n\n## Purpose\n        The purpose of this codebook is to explain the sources and the subsequent\n        transformations of the dataset(s) used in the project for the course \"Getting\n        and Cleaning Data.\"\n\n## Objectives\n        The objectives were the following:\n        \n        The creation of one R script called run_analysis.R which does the following:\n        \n        1.Merges the training and the test sets to create one data set.  \n        \n        2.Extracts only the measurements on the mean and standard deviation for each\n                measurement.  \n        3.Uses descriptive activity names to name the activities in the data set.  \n        \n        4.Appropriately labels the data set with descriptive variable names.  \n        \n        5.From the data set in step 4, creates a second, independent tidy data set with\n                the average of each variable for each activity and each subject.\n        \n        A full description is available at the site where the data was obtained: \n        \nhttp://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones \n        \n        Here is the data for the project: \n        \nhttps://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip \n\n##  Description of Work\n\n        There are 3 phases to the code:\n        \n### Phase 1 ###\n          Set up libraries\n          Set up temporary variables\n          Delete possible old data.  Download data\n          Unzip freshly downloaded data\n          Begin transforming data sets until the Test and Training data sets\n              can be combined to include descriptive activity names\n              and descriptive feature names for the variable labels\n\n### Phase 2  ###\n\n          Extracting only the measurements on the mean and standard deviation \n                for each measurement.\n          \n          This will create a second tidy dataset.  A subset of which will contain\n                  only those variables out of the 564 variables in the all.data dataset\n                  which have \"mean\" or \"std\" found in the header name for each of the\n                  subjects at each of their Activities.\n  \n\n###  Phase 3 ###\n\n           Calculates the means for those features which had \"mean\" or \"std\"\n                in their descriptive name.\n           \n           Resorts the new dataset of this summary data so that it is reported\n                in ascending order of Subject Number with their Activity in alphabetical\n                order.\n           \n           Creates the final output file\n\n\n\n##  Temporary tables\n\n### Phase 1  ###\n\n        dataset_url holds the URL of the data to be downloaded\n        \n        features.list - takes the data from the features.txt file.  These are the\n                headers for the data itself.  \n                \n        activity.labels - takes the data from the activity_labels.txt file\n        \n        y.test - takes Activity Number  from the Test dataset\n        x.test - takes the data set from the Test dataset\n        subject.test - takes the subject number from the Test dataset\n        \n        y.train - takes Activity Number  from the train dataset\n        x.train - takes the data set from the train dataset\n        subject.train - takes the subject number from the train dataset\n        \n        names for train and test.data come from the features.list$V2    \n        \n        activity.test - is created from merging the Activity Number with the Activity\n                Label on the activity.num field\n                        \n        test.data - is created from merging activity and subject data with the test data\n                on a rownum field for the TEST dataset\n                        \n        activity.train - is created from merging the Activity Number with the Activity\n                Label on the activity.num field\n                        \n        train.data - is created from merging activity and subject data with the train\n                data on a rownum field for the train dataset\n                        \n        all.data - is created by binding the rows from test.data and train.data \n\n##  Phase 2 ###\nsimple.id - a table created from a subset of all.data for the columns rownum,Subject,\n                & Activity.  This is to be used to create a new sort order of the\n                final results by Subject and Activity for the selected columns of\n                information\n\nsimple - table created from simple.id after a concatenation of Subject & Activity\n                is made.  This is tied to a unique rownum(ber) of the data.\n                \nall.mean - a table created from a subset of all.data for the columns with the phrase\n                \"mean\" in the Feature name.\n\nall.std - a table created from a subset of all.data for the columns with the phrase\n                \"std\" in the Feature name.    \n\nto.process - table created from merging the columns from all.mean and all.std by rownum\n                and then simple is added back in to return the subject, activity,\n                and the concatenated SubjectActivity\n                \n## Phase 3  ####\n\nSA - a list created from the distinct values of Subject + Activity.  This is to be\n                used for the aggregation function.\n\nresult - table created from the aggregate function of the to.process table.  The\n                mean function is applied to all the columns grouped by the row grouping\n                of Subject + Activity.\n\nsorted - temporary table used to hold the sorted data of Subject then Activity\n                which is then used to create a sequence number.\n                \nfinished.result - The aggregated table result is sorted for a numeric sort of\n                Subject number then Activity in alphabetical order.\n                \n \n##  Additional Vectors added\n$rownum - field added to the various datasets to keep the datasets aligned during\n        binding and merging process\n\n\n##Output Files\none_dataset.csv - will be written to the working directory.  This contains \n        10,299 observations 565 variables from the Test and Training datasets with\n        descriptive headers for the columns and rows identifying subject and Activity.\n        \nfinished_result.csv - will be written to the working directory.  This contains\n        180 observations of 80 variables which are the mean calculations for each of\n        the Features which had either the phrase \"mean\" or \"std\" in them.  The means\n        are calculated at each Activity level for each Subject.\n\n",
    "created" : 1413640629405.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "1690806778",
    "id" : "C2427148",
    "lastKnownWriteTime" : 1414102646,
    "path" : "~/coursera/Getting-Cleaning-Data-Project/CodeBook.md",
    "project_path" : "CodeBook.md",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "markdown"
}