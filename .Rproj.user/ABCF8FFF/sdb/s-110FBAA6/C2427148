{
    "contents" : "# Code Book for Getting and Cleaning Data Project\n\n\n### by andrea345\n\n\n## Purpose\n        The purpose of this codebook is to explain the sources and the subsequent\n        transformations of the dataset(s) used in the project for the course \"Getting\n        and Cleaning Data.\"\n\n## Objectives\n        The objectives were the following:\n        \n        The creation of one R script called run_analysis.R which does the following:\n        \n        1.Merges the training and the test sets to create one data set.  \n        \n        2.Extracts only the measurements on the mean and standard deviation for each\n                measurement.  \n        3.Uses descriptive activity names to name the activities in the data set.  \n        \n        4.Appropriately labels the data set with descriptive variable names.  \n        \n        5.From the data set in step 4, creates a second, independent tidy data set with\n                the average of each variable for each activity and each subject.\n        \n        A full description of the raw datasets is available at the site where the data was obtained: \n        \nhttp://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones \n        \n        Here is the data for the project: \n        \nhttps://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip \n\n        Attribution and information from their dataset is found at the bottom of this document.\n\n\n\n##  Description of Work\n\n        There are 3 phases to the code:\n        \n### Phase 1 ###\n          Set up libraries\n          Set up temporary variables\n          Delete possible old data.  Download data\n          Unzip freshly downloaded data\n          Begin transforming data sets until the Test and Training data sets\n              can be combined to include descriptive activity names\n              and descriptive feature names for the variable labels\n\n### Phase 2  ###\n\n          Extracting only the measurements on the mean and standard deviation \n                for each measurement.\n          \n          This will create a second tidy dataset.  A subset of which will contain\n                  only those variables out of the 564 variables in the all.data dataset\n                  which have \"mean\" or \"std\" found in the header name for each of the\n                  subjects at each of their Activities.\n  \n\n###  Phase 3 ###\n\n           Calculates the means for those features which had \"mean\" or \"std\"\n                in their descriptive name.\n           \n           Resorts the new dataset of this summary data so that it is reported\n                in ascending order of Subject Number with their Activity in alphabetical\n                order.\n           \n           Creates the final output file\n\n\n\n##  Temporary tables\n\n### Phase 1  ###\n\n        dataset_url holds the URL of the data to be downloaded\n        \n        features.list - takes the data from the features.txt file.  These are the\n                headers for the data itself.  \n                \n        activity.labels - takes the data from the activity_labels.txt file\n        \n        y.test - takes Activity Number  from the Test dataset\n        x.test - takes the data set from the Test dataset\n        subject.test - takes the subject number from the Test dataset\n        \n        y.train - takes Activity Number  from the train dataset\n        x.train - takes the data set from the train dataset\n        subject.train - takes the subject number from the train dataset\n        \n        names for train and test.data come from the features.list$V2    \n        \n        activity.test - is created from merging the Activity Number with the Activity\n                Label on the activity.num field\n                        \n        test.data - is created from merging activity and subject data with the test data\n                on a rownum field for the TEST dataset\n                        \n        activity.train - is created from merging the Activity Number with the Activity\n                Label on the activity.num field\n                        \n        train.data - is created from merging activity and subject data with the train\n                data on a rownum field for the train dataset\n                        \n        all.data - is created by binding the rows from test.data and train.data \n\n##  Phase 2 ###\n        simple.id - a table created from a subset of all.data for the columns rownum,Subject,\n                        & Activity.  This is to be used to create a new sort order of the\n                        final results by Subject and Activity for the selected columns of\n                        information\n        \n        simple - table created from simple.id after a concatenation of Subject & Activity\n                        is made.  This is tied to a unique rownum(ber) of the data.\n                        \n        all.mean - a table created from a subset of all.data for the columns with the phrase\n                        \"mean\" in the Feature name.\n        \n        all.std - a table created from a subset of all.data for the columns with the phrase\n                        \"std\" in the Feature name.    \n        \n        to.process - table created from merging the columns from all.mean and all.std by rownum\n                        and then simple is added back in to return the subject, activity,\n                        and the concatenated SubjectActivity\n                \n## Phase 3  ####\n\n        SA - a list created from the distinct values of Subject + Activity.  This is to be\n                        used for the aggregation function.\n        \n        result - table created from the aggregate function of the to.process table.  The\n                        mean function is applied to all the columns grouped by the row grouping\n                        of Subject + Activity.\n        \n        sorted - temporary table used to hold the sorted data of Subject then Activity\n                        which is then used to create a sequence number.\n                        \n        finished.result - The aggregated table result is sorted for a numeric sort of\n                        Subject number then Activity in alphabetical order.\n                        \n \n##  Additional Vectors added\n        $rownum - field added to the various datasets to keep the datasets aligned                 \n                during binding and merging process\n        \n        $SubjectActivity - a field created from the concatenation of the Subject number\n                plus the Activity Label.  This is created so the summarization process\n                can be shorted from two iterations to a single one.\n                \n        \n##  Output Files\n\n        All output files will be written in .txt format with row.names = FALSE\n        \n        one_dataset.txt - will be written to the working directory.  This contains \n                10,299 observations 565 variables from the Test and Training datasets with\n                descriptive headers for the columns and rows identifying subject and Activity.\n                \n        finished_result.txt - will be written to the working directory.  This contains\n                180 observations of 80 variables which are the mean calculations for each of\n                the Features which had either the phrase \"mean\" or \"std\" in them.  The means\n                are calculated at each Activity level for each Subject.\n\n\n##  Original documentation for the dataset and attribution\n\n        \n        Abstract: Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n          \n        \n        Source:\n        \n        Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto. \n        Smartlab - Non Linear Complex Systems Laboratory \n        DITEN - Universit√É  degli Studi di Genova, Genoa I-16145, Italy. \n        activityrecognition '@' smartlab.ws \n        www.smartlab.ws \n\n\n\n\n        Data Set Information:\n        \n        The experiments have been carried out with a group of 30 volunteers within an\n        age bracket of 19-48 years. Each person performed six activities (WALKING,\n        WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a\n        smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer\n        and gyroscope, we captured 3-axial linear acceleration and 3-axial angular\n        velocity at a constant rate of 50Hz. The experiments have been video-recorded\n        to label the data manually. The obtained dataset has been randomly partitioned\n        into two sets, where 70% of the volunteers was selected for generating the\n        training data and 30% the test data. \n        \n        The sensor signals (accelerometer and gyroscope) were pre-processed by applying\n        noise filters and then sampled in fixed-width sliding windows of 2.56 sec and\n        50% overlap (128 readings/window). The sensor acceleration signal, which has\n        gravitational and body motion components, was separated using a Butterworth\n        low-pass filter into body acceleration and gravity. The gravitational force\n        is assumed to have only low frequency components, therefore a filter with\n        0.3 Hz cutoff frequency was used. From each window, a vector of features\n        was obtained by calculating variables from the time and frequency domain. \n        \n        Check the README.txt file for further details about this dataset. \n\n\n        Attribute Information:\n        \n        For each record in the dataset it is provided: \n        - Triaxial acceleration from the accelerometer (total acceleration) and\n        the estimated body acceleration. \n        - Triaxial Angular velocity from the gyroscope. \n        - A 561-feature vector with time and frequency domain variables. \n        - Its activity label. \n        - An identifier of the subject who carried out the experiment. \n        \n        \n        Relevant Papers:\n        \n        N/A\n        \n         \n        \n        Citation Request:\n        \n        [1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes\n        -Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware\n        -Friendly Support Vector Machine. International Workshop of Ambient Assisted\n        Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012\n        \n",
    "created" : 1413640629405.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "3333578124",
    "id" : "C2427148",
    "lastKnownWriteTime" : 1414121750,
    "path" : "~/coursera/Getting-Cleaning-Data-Project/CodeBook.md",
    "project_path" : "CodeBook.md",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "markdown"
}